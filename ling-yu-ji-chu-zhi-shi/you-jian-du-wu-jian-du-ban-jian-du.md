# SSL: 半监督学习

Semi-Supervised Learning， SSL是半监督学习的缩写。半监督学习不像强化学习一样依赖外界交互，而是通过利用未标记样本来提升模型的性能，主要思想在于关注如何利用大量无标注数据的信息和少量有标注数据的信息进行监督学习。训练数据中同时有有标签数据和无标签数据，一般假设，无标签数据比有标签数据多得多。

[半监督学习笔记1](https://zhuanlan.zhihu.com/p/411533418)

[半监督学习笔记2](https://zhuanlan.zhihu.com/p/412090424)

[综述](https://www.cnblogs.com/picassooo/p/14923333.html)

[半监督学习！写的很全面，但似乎有点老？](https://zhuanlan.zhihu.com/p/349107869)

[计算机视觉中的半监督学习（图画得很清楚，细节比较少）](https://blog.csdn.net/weixin_51697828/article/details/122616023)

[半监督论文整理，不是很全，但感觉囊括了基础的论文](https://zhuanlan.zhihu.com/p/500781774)

## 相关问题

### 主动学习

主动学习是通过人类专家获取未标注数据的GT，半监督学习是通过机器自己来综合利用未标注数据给出的信息，没有人类专家参与

### 迁移学习和域适应

半监督学习和无监督学习域适应最大的不同就是，半监督学习中所有的数据都来自于同样的分布，但是域适应的两个数据集来自于不同的分布。

但是这两个领域的方法都是都是可以相互应用的，其实迁移学习和半监督学习所做的事情非常类似

### 弱监督学习

目标检测中精确的label换为不那么精确的label，利用不那么精确的label来学习

## 三大假设

半监督学习的思想基于下面三大假设：

1. smoothness assumption

   如果两个样本在输入的空间中距离近，那么对应的标签应该相同

   位于稠密数据区域的两个距离很近的样例的类标签相似

2. low-density assumption：分类的决策边界不应该穿过高密度的区域，而是应该穿过低密度的区域

   也有说cluster assumption的：标签相同的样本对应的样本也应该聚类在一个cluster里面；如果样本点在同一簇中，它们很可能属于同一类

   实际上聚类假设属于平滑假设的一个特例，在平滑假设中，样本不一定要形成明显的簇，例如整个样本空间都是稠密且均匀的，此时就没有了聚类的簇的概念，当样本空间中形成明显的簇时，聚类假设则派上用场

3. manifold assumption：在高维空间中相近的样本在低维的流形中也相近；

   首先我们需要知道当特征的维度非常高的时候会出现维度诅咒的问题，即，在高维空间，距离度量的计算失效，此时密度和距离的概念趋于无效，则上述两大假设难以成立，所以流形假设这样说：

   如果高维样本恰好可以映射到一个低维的流形结构上，此时在低维的流型空间中，前两大假设仍旧是可以成立的

在三大假设下，没有标签的数据可以通过分布提供一定的信息。



主要的半监督学习方法分类

- 基于一致性的
- 基于图的
- 基于对抗的
- 其他

- 生成方法



## 方法类别



### 基于一致性的方法

consistency learning是半监督学习常用的一种思想：同一样本经过不同的变换或扰动后，网络对变换前后的输出应该是相似的

一致性正则化consistency regularization



一致性正则化模型：

1. Ladder Networks

   基本思想：对输入x加噪后编码，然后再解码得到的结果应该和输入x不加噪编码得到的结果相似。使用这个思想构造无监督损失对模型进行约束。

2. Pi-Model

   基本思想：一个输入 x及其标签 y , x 经过增强后产生两个输出 (x1)̃ 和(x2)̃ ，经过一个带有dropout层的神经网络之后输出两个值 (y1)̃ 和 (y2)̃，这两个值应该相近。

   也就是每个epoch中将同一个样本通过数据增强和网络dropout添加扰动，输入网络后得到的两个预测结果基于一致性应该保持相似，使用这个思想构造无监督损失对模型进行约束。

3. 时间集成（Temporal Ensembling）

   Pi-Model只考虑了单个minibatch的输入，minibatch的分布不能有效的反应真实数据分布，所以使用多个minibatch共同训练，相互影响，才能对真实数据的分布估计的更加准确。

   因此时间集成方法对每一个输出y都计算之前数据值与当前值的加权平均。

   时序集成的基本思想是同一个样本在训练的不同epoch中经过不同的数据增强和网络dropout后得到的预测结果基于一致性应该保持相似，因此时序集成方法对每一个训练样本计算一个指数移动平均（EMA）预测，并在每一个epoch后用最新的预测对其进行更新。通过EMA得到的预测集成了模型之前的所有预测和最新得到的预测结果。yema是EMA预测结果

   ![image-20221224113145256](https://nikki-article-pic.oss-cn-beijing.aliyuncs.com/img/EMA.png)

   权重的影响：假设 α 值设的很大，那么新的新学到的信息需要完全被模型考虑到，需要经过很长的时间。而 α 值设的很小，之前的信息又不会被考虑的那么充分，那么导致一次的误差只会在一次minibatch训练中得到更新

4. Mean Teachers

   对模型的参数做指数加权平均

5. Dual Student

   MT存在的问题：随着训练次数的不断增加，每一次参数的更新也在不断的减小，再利用指数加权平均的方法，teacher-model最终会收敛至student-model

   两个模型的输出应该接近，每次迭代选择更不稳定的模型去更新

#### 对抗样本

VAT

[VAT解读](http://www.twistedwg.com/2018/12/04/VAT.html)

### self training（伪标签Pseudo label）

#### 基本思想

在已标记的数据上训练，然后对未标注数据进行预测，取预测置信度最高的样本直接对其进行标签定义，然后将这类样本纳入当前训练样本中继续训练，直到模型的预测结果不再发生变化

#### 伪标签

- 硬标签：人工确定给定标签的阈值

  [代码实现1](https://link.zhihu.com/?target=https%3A//github.com/tmadl/semisup-learn)

  [代码实现2](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1503.00269)

- 软标签：根据概率对样本的权重进行定义（标签的mixup）

  举例如下：在二分类问题中，模型对样本A预测的概率为0.4与0.6，则我们将A当作两个样本：标签为0的样本其权重为0.4，标签为1的样本其权重为0.6。将这两个样本加入原始的数据进行训练和迭代直到收敛或达到预先定义的停止条件为止

#### 细节理解

上述过程相当于用模型自己给出的信息做一个数据增广，在竞赛中是不少选手会用到的一种数据增强提高模型泛化性的技巧，在结构化数据中应用相对较少。这种方法对于初始模型和数据的精度要求较高，只有初始和后续的类别正确的标记了绝大多数样本时，才能通过迭代改进分类的精度，否则标签预测错误会导致性能下降。

#### 存在的问题

- 噪声标签

  即使高精度模型也不可避免会添加错误标记，带来噪声标签，目前有一定的解决方法提出：

  - 标签去噪
  - 对前期的无监督损失设置比较少的权重，到后面预测相对准确时慢慢增大权重，但权重如何设置和更新也是个问题

- 对类别数据分布不均衡的问题，基于可信度给出的伪标签会更偏向于多数类，给后续学习带来严重的偏差

  - ACPL的解决方法：选出高信息量的来打标签

    感觉这种思想是结合了主动学习的想法

### 生成式模型

代表方法：半监督版的高斯混合模型

这部分不是特别理解，稍后再看看

#### 基本思想

假设所有数据均由相同的生成式模型产生，借助模型参数将未标记数据与学习目标联系起来，通常利用 EM 算法根据极大似然来估计模型参数

### 基于图的算法



### 混合方法



## 现在基本已经过时的方法

### 低密度分离

代表方法：S3VM、TSVM

#### 基本思想

通过调整SVM的超平面和未标记数据的标记指派，使得SVM在所有训练数f包括有标记和未标记数据上最大化间隔 （Margin)

#### 存在的问题

计算效率低

### 基于分歧的方法

这部分有什么实际的应用方法吗？好像近几年没什么用了？先忽略吧

可以分为多视图学习和单视图学习。由于多视图学习的基本假设（视图的条件独立性）过于严苛，在大部分场景中基本都不满足，所以这里不深入探究，所以下面主要介绍的是单视图学习。

#### 基本思想

通过多个学习器（模型）来对未标记数据进行利用。

训练方法：co-training，tri-traiing，协同森林法

## 相关论文

### Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks

是一篇发表在 ICML 2013 的文章，（可能）是最早的用伪标签Pseudo label方式半监督学习的方法。

### Semi-Supervised Learning with Ladder Networks

2015年诞生半监督 ladderNet，ladderNet是其他文章中先提出来的想法，但这篇文章通过 skip connection 使它work in semi-supervised fashion，而且效果非常好，达到了当时的 state-of-the-art 性能。

在这之前很多半监督深度学习算法是用无监督预训练这种方式对无标签数据进行利用的，但事实上，这种把无监督学习强加在有监督学习上的方式有缺点：两种学习的目的不一致，其实并不能很好兼容。这篇文章认为，无监督预训练一般是用重构样本进行训练，其编码（学习特征）的目的是尽可能地保留样本的信息；而有监督学习是用于分类，希望只保留其本质特征，去除不必要的特征。

### A Simple Semi-Supervised Learning Framework for Object Detection

google

问题：

1.  多类别和多标签的区别?

    multi-label是一张图片有多个label multi-class是一张图片一个类别，但是总的类别数量很多（超过2）
2.  半监督学习具体的训练流程？

    是同时对有标注的数据计算损失更新模型，然后对无标注的数据预测伪标签保存吗？

    还是先对有标注数据计算更新模型之后，再对无标注数据生成一批伪标签？

### ACPL

找hard sample：是度量学习的思想；如何找hard sample：信息量，距离（这个思想在度量学习里面很常规）

优先学习hard sample：anti-curriculum的思想

伪标签筛选：半监督，大部分论文都在回答如何选择可信的/打出可信的伪标签，而没有思考哪些样本最需要打伪标签

本文将hard sample和伪标签结合起来：给hard sample打伪标签

如何打出可信的伪标签：mixup



Anti-curriculum Pseudo-labelling for Semi-supervised Medical Image Classification（CVPR 2022）

[代码](https://github.com/FBLADL/ACPL)

医学图像分析中普遍存在两个问题，一个是多类别和多标签，另一个是类别不均衡。常用的半监督学习策略可以分为基于consistency learning的和自监督预训练的，还有伪标签的？

一般应用于医学图像的半监督学习策略是伪标签，这种策略存在如下问题：

1. 在面对多类别多标签和类别不平衡时存在的问题：分类器会偏向给出样本数量多的类别标签，会恶化样本数少的类别的分类精度。以往的论文对所有类都使用固定的伪标签选择阈值，显然这是不合理的，所以最好是有一种class-wise的阈值，来解决上述问题。但是在实际场景中这种class-wise的阈值很难估计；
2. 所有伪标签都存在的问题：错误的伪标签会增强模型对错误预测的可信度，降低模型精度

本文针对多分类多标签和类别不均衡的半监督医学图像分析提出一种新的方法，主要思想如下

1.  选择the most informative unlabeled images 来进行伪标记，对于如何选择informative unlabeled samples，提出一种信息度量方式：cross-distribution sample informativeness（CDSI）

    这基于之前的研究的观点：对于SSL，在 unlabeled and labeled samples 之间存在一个 distribution shift，在训练过程中，distribution shift会导致模型学不好，所以更有效的学习方法应该是关注学习尽可能远离labelled samples 分布的informative unlabeled samples，对它们打伪标签；同时这些样本也很可能属于样本数少的类别，对这些样本进行关注也就避免了估计class-wise的阈值的需要但还能解决类别分布不平衡问题。

    一个有效的 learning curriculum 必须关注于尽可能远离 labelled samples 分布的 informative unlabeled samples
2.  提出一种新的伪标签机制：informative mixup（IM）

    mixup模型给出的标签和KNN给出的标签（K近邻标签的均值）

    权重取计算出来的特征x的信息密度（一般大于0.5，算出来观察得到的）
3.  提出anchor set purification，ASP钝化方法

    选择 informative pseudo-labelled 样本，并将它们包含在 labelled anchor set，以提高KNN分类器的伪标记精度

创新：有研究使用Curriculum learning来研究pseudo-labelling SSL 方法，但是还没有人使用anti-curriculum learning来研究SSL方法。

```
CDSI: cross-distribution sample informativeness 度量样本信息量的方法
IM: informative mixup  给出伪标签的机制
ASP: anchor set purification 更新anchor set的方法
```





## 一些想法和思考

对抗学习的思想构造对抗样本，对抗样本如何给出伪标签？用找对抗样本的思想来找无标注样本打标签，也就是对于目前的有标注样本x来说，对其添加一个微小扰动s得到x'，如果有无标注样本和x'接近，那么该无标注样本就是更有价值，更具信息量的，值得优先关注；问题是：如何找对抗样本？需要是微小扰动，保证其标签不变，需要模型判断出错。那如何对无标注样本打出正确的伪标签？
